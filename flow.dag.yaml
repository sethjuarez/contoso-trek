id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    default: []
  question:
    type: string
    is_chat_input: true
    default: What can you tell me about your jackets?
  customerId:
    type: string
    default: "2"
outputs:
  answer:
    type: string
    reference: ${llm_response.output}
    is_chat_output: true
  context:
    type: string
    reference: ${retrieve_documentation.output}
nodes:
- name: question_embedding
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: isis-connection
    input: ${inputs.question}
    deployment_name: text-embedding-ada-002
- name: retrieve_documentation
  type: python
  source:
    type: code
    path: retrieve_documentation.py
  inputs:
    search: contoso-search
    question: ${inputs.question}
    index_name: contoso-products
    embedding: ${question_embedding.output}
- name: llm_response
  type: llm
  source:
    type: code
    path: llm_response.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    prompt_text: ${customer_prompt.output}
    question: ${inputs.question}
  connection: isis-connection
  api: chat
- name: customer_lookup
  type: python
  source:
    type: code
    path: customer_lookup.py
  inputs:
    conn: contoso-cosmosdb
    customerId: ${inputs.customerId}
- name: customer_prompt
  type: prompt
  source:
    type: code
    path: customer_prompt.jinja2
  inputs:
    documentation: ${retrieve_documentation.output}
    history: ${inputs.chat_history}
    customer: ${customer_lookup.output}
